# 复制为 .env 后按需修改，docker compose 会读取
# cp .system/.env.example .system/.env

# ── 挂载根目录 ────────────────────────────────────────
# 容器数据目录的宿主机根路径，下面会创建 workspace_data、openclaw_data、postgres_data 子目录
# 修改此项可将所有容器数据统一存放到指定位置
MOUNT_ROOT=

# ── 镜像版本 ──────────────────────────────────────────
# 构建时写入镜像标签，也可命令行覆盖：VERSION=1.0.0 docker compose up -d --build
VERSION=latest

# ── Postgres ────────────────────────────────────────────
POSTGRES_USER=dev
POSTGRES_PASSWORD=dev
POSTGRES_DB=app

# ── LLM Providers ────────────────────────────────────────
#
# 自定义 OpenAI-compatible 提供商配置。
# 格式：LLM_PROVIDER_{NAME}_BASE_URL / _API_KEY / _MODELS
#   NAME  = 自定义 provider 名（大写字母+数字，将转小写作为 OpenClaw 中的 provider id）
#   MODELS = 逗号分隔的模型 ID 列表，第一个为该 provider 的默认模型
#
# 示例引用模型：agents.defaults.model.primary = "ark/deepseek-v3.2"
#
# 可配置多个 provider，entrypoint 会自动注入 openclaw.json。
# 详见 docs/LLM-PROVIDERS.md
#

# 火山引擎（ARK）— DeepSeek 等
# LLM_PROVIDER_ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/coding
# LLM_PROVIDER_ARK_API_KEY=
# LLM_PROVIDER_ARK_MODELS=deepseek-v3.2

# 智谱 AI（GLM）
# LLM_PROVIDER_GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# LLM_PROVIDER_GLM_API_KEY=
# LLM_PROVIDER_GLM_MODELS=glm-4.7

# 默认主力模型（格式：provider_name/model_id）
# Qwen Portal（OAuth 免费）也可以用，需要在容器内执行 openclaw models auth login --provider qwen-portal
LLM_PRIMARY_MODEL=

# Embedding（用于 memory search 的向量化）
# EMBEDDING_API_KEY 必填，BASE_URL 和 MODEL 可选（有默认值）
# 默认使用智谱 embedding-3，可复用 GLM 的 API Key
EMBEDDING_API_KEY=
# EMBEDDING_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
# EMBEDDING_MODEL=embedding-3

# ── OpenClaw Gateway ───────────────────────────────────
# Gateway 认证 token（可选，建议生产环境设置）
OPENCLAW_GATEWAY_TOKEN=

# ── SSH 远程登录（端口 10220）────────────────────────────
# 设置后容器内将启动 sshd，可用 root + 此密码 SSH 登录：ssh -p 10220 root@<主机>
ROOT_PASSWORD=

# ── 飞书 (Feishu) Channel ──────────────────────────────
# 在飞书开放平台创建应用后获取
# 详见 docs/FEISHU-CHANNEL-SETUP.md
FEISHU_APP_ID=
FEISHU_APP_SECRET=
